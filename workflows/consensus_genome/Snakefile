"""
Snakefile for consensus genome workflow.
"""

import json

from src.defs import PROJECT_ROOT_TAG, INPUT_DICT_TAG, LOG_PATH_TAG, FAIL_MESSAGE
from src.logging_utils import get_logger, set_log_file

get_logger().info("Consensus genome snakefile start.")

if PROJECT_ROOT_TAG not in config:
    raise ValueError("Missing project root tag in config.")
project_root = config[PROJECT_ROOT_TAG]

if INPUT_DICT_TAG not in config:
    raise ValueError("input_dict must be provided via --config")
input_dict = json.loads(config[INPUT_DICT_TAG])
samples = list(input_dict.keys())

log_path = config.get(LOG_PATH_TAG, "logs/consensus_genome.log")
set_log_file(log_path)

output_dir = config.get("output_dir", "output")
fastp_report_json = config.get("fastp_report_json", "output/fastp_report.json")

rule all:
    input:
        expand("logs/{sample}.log", sample=samples)


# rule validate_input:
#     input:
#         lambda wildcards: input_dict[wildcards.sample]["R1"],
#         lambda wildcards: input_dict[wildcards.sample].get("R2", None)
#     output:
#         temp("logs/{sample}_input_validated.log")
#     threads: 1  # Simple task, 1 thread is fine
#     shell:
#         """
#         echo "Validating input for {wildcards.sample}" > {output}
#         """

rule create_log:
    output:
        "logs/{sample}.log"
    threads: 1  # Simple task, 1 thread is fine
    shell:
        """
        touch {output}
        echo "Created log for {wildcards.sample}" > {output}
        """

# rule dump_config:
#     output:
#         "logs/config_dump.txt"  # File where the config will be written
#     run:
#         logger = get_logger(log_file=log_path)
#         logger.info("dump config")
#         with open(output[0], "w") as f:
#             f.write(json.dumps(config, indent=2))
#
#
# rule all:
#     input:
#         "config_dump.txt"
#     shell:
#         """
#         echo 'Test'
#
#         """
    # echo'Test' > {log_path}
# rule all:
#     input:
#         f"{OUTPUT_DIR}/trimmed_R1.fastq",
#         f"{OUTPUT_DIR}/trimmed_R2.fastq",
#         FASTP_REPORT_JSON
#     output:
#         "data/output/consensus_genome.done"
#     params:
#         max_reads = config.get("max_reads")
#     log:
#         "consensus_genome.log"
#     shell:
#         """
#         echo "Processing {FASTQ1}" > {output} 2>> {log}
#         echo "Finished processing" >> {log}
#         """


# rule trim_with_fastp:
#     input:
#         fq1=FASTQ1,
#         fq2=FASTQ2 if FASTQ2 else []  # Empty list if FASTQ2 is None
#     output:
#         out_fq1=f"{OUTPUT_DIR}/trimmed_R1.fastq",
#         out_fq2=f"{OUTPUT_DIR}/trimmed_R2.fastq" if FASTQ2 else temp(f"{OUTPUT_DIR}/trimmed_R2.fastq"),  # Conditional output
#         json=FASTP_REPORT_JSON
#
#     params:
#         fastp_cmd=lambda wildcards, input, output: (
#             f"fastp -i {input.fq1} -I {input.fq2} -o {output.out_fq1} -O {output.out_fq2} --json {output.json}"
#             if FASTQ2 else
#             f"fastp -i {input.fq1} -o {output.out_fq1} --json {output.json}"
#         )
#     log:
#         "consensus_genome.log"
#     shell:
#         """
#         {params.fastp_cmd} 2> {log}
#         """
#
# onstart:
#     logger.info(f"Starting consensus genome pipeline.")
#     print("\nStarting consensus genome pipeline...")
#
# onerror:
#     logger.error("Consensus genome pipeline failed. Check the log file %s for details.", log_file)
#     logger.error("Error message: %s", fail_message)
#     print("\nERROR: Consensus genome pipeline failed!")
#     print(f"Reason: {fail_message}")
#
# onsuccess:
#     logger.info("Consensus genome pipeline completed successfully!")
#     print("\nSUCCESS: Consensus genome pipeline finished without errors.")
